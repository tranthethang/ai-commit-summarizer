[general]
active_provider = "gemini"
max_diff_length = 36000

[ai_params]
num_predict = 250
temperature = 0.1
top_p = 0.9

[gemini]
api_key = ""
api_model = "gemini-2.0-flash"
model = "gemini-2.0-flash"

[ollama]
model = "qwen2.5-coder:3b"
url = "http://localhost:11434/api/generate"
